{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanwljamie/Automatic-KG-Construction/blob/main/KGE_ESZSL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_dir = '/content/gdrive/MyDrive/caltech_birds-master/Caltech-Birddata_full/CUB_200_2011/'"
      ],
      "metadata": {
        "id": "DIHdlcgszSed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ampligraph"
      ],
      "metadata": {
        "id": "du2fgeIS_9Fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ampligraph; "
      ],
      "metadata": {
        "id": "JzgfzqAp__Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ampligraph\n",
        "\n",
        "ampligraph.__version__"
      ],
      "metadata": {
        "id": "-2UpU-8BAKVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "from ampligraph.datasets import load_from_csv, load_from_ntriples, load_from_rdf\n",
        "X = load_from_ntriples('/content/gdrive/MyDrive/caltech_birds-master/','all_type_labelgraph_31jul.nt')\n"
      ],
      "metadata": {
        "id": "Xtx-pnRvASuB"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entities = np.unique(np.concatenate([X[:, 0], X[:, 2]]))[:200]\n",
        "print(entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Uo_6kp8AS3l",
        "outputId": "bba78931-5b2c-44b7-b088-51b7c2da9624"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1-D extent^^<http://www.w3' '2-D shape^^<http://www.w3'\n",
            " '<http://example.org/AcadianFlycatcher>'\n",
            " '<http://example.org/AmericanCrow>'\n",
            " '<http://example.org/AmericanGoldfinch>'\n",
            " '<http://example.org/AmericanPipit>'\n",
            " '<http://example.org/AmericanRedstart>'\n",
            " '<http://example.org/AmericanThreetoedWoodpecker>'\n",
            " '<http://example.org/AnnaHummingbird>' '<http://example.org/ArticTern>'\n",
            " '<http://example.org/BairdSparrow>'\n",
            " '<http://example.org/BaltimoreOriole>' '<http://example.org/BankSwallow>'\n",
            " '<http://example.org/BarnSwallow>'\n",
            " '<http://example.org/BaybreastedWarbler>'\n",
            " '<http://example.org/BeltedKingfisher>' '<http://example.org/BewickWren>'\n",
            " '<http://example.org/BlackTern>'\n",
            " '<http://example.org/BlackandwhiteWarbler>'\n",
            " '<http://example.org/BlackbilledCuckoo>'\n",
            " '<http://example.org/BlackcappedVireo>'\n",
            " '<http://example.org/BlackfootedAlbatross>'\n",
            " '<http://example.org/BlackthroatedBlueWarbler>'\n",
            " '<http://example.org/BlackthroatedSparrow>'\n",
            " '<http://example.org/BlueGrosbeak>' '<http://example.org/BlueJay>'\n",
            " '<http://example.org/BlueheadedVireo>'\n",
            " '<http://example.org/BluewingedWarbler>'\n",
            " '<http://example.org/BoattailedGrackle>' '<http://example.org/Bobolink>'\n",
            " '<http://example.org/BohemianWaxwing>'\n",
            " '<http://example.org/BrandtCormorant>'\n",
            " '<http://example.org/BrewerBlackbird>'\n",
            " '<http://example.org/BrewerSparrow>'\n",
            " '<http://example.org/BronzedCowbird>' '<http://example.org/BrownCreeper>'\n",
            " '<http://example.org/BrownPelican>' '<http://example.org/BrownThrasher>'\n",
            " '<http://example.org/CactusWren>' '<http://example.org/CaliforniaGull>'\n",
            " '<http://example.org/CanadaWarbler>'\n",
            " '<http://example.org/CapeGlossyStarling>'\n",
            " '<http://example.org/CapeMayWarbler>' '<http://example.org/Cardinal>'\n",
            " '<http://example.org/CarolinaWren>' '<http://example.org/CaspianTern>'\n",
            " '<http://example.org/CedarWaxwing>'\n",
            " '<http://example.org/CeruleanWarbler>'\n",
            " '<http://example.org/ChestnutsidedWarbler>'\n",
            " '<http://example.org/ChippingSparrow>'\n",
            " '<http://example.org/ChuckwillWidow>'\n",
            " '<http://example.org/ClarkNutcracker>'\n",
            " '<http://example.org/ClaycoloredSparrow>'\n",
            " '<http://example.org/CliffSwallow>' '<http://example.org/CommonRaven>'\n",
            " '<http://example.org/CommonTern>'\n",
            " '<http://example.org/CommonYellowthroat>'\n",
            " '<http://example.org/CrestedAuklet>' '<http://example.org/DarkeyedJunco>'\n",
            " '<http://example.org/DownyWoodpecker>' '<http://example.org/EaredGrebe>'\n",
            " '<http://example.org/EasternTowhee>' '<http://example.org/ElegantTern>'\n",
            " '<http://example.org/EuropeanGoldfinch>'\n",
            " '<http://example.org/EveningGrosbeak>'\n",
            " '<http://example.org/FieldSparrow>' '<http://example.org/FishCrow>'\n",
            " '<http://example.org/FloridaJay>' '<http://example.org/ForstersTern>'\n",
            " '<http://example.org/FoxSparrow>' '<http://example.org/Frigatebird>'\n",
            " '<http://example.org/Gadwall>' '<http://example.org/Geococcyx>'\n",
            " '<http://example.org/GlaucouswingedGull>'\n",
            " '<http://example.org/GoldenwingedWarbler>'\n",
            " '<http://example.org/GrasshopperSparrow>'\n",
            " '<http://example.org/GreatCrestedFlycatcher>'\n",
            " '<http://example.org/GreatGreyShrike>' '<http://example.org/GreenJay>'\n",
            " '<http://example.org/GreenKingfisher>'\n",
            " '<http://example.org/GreenVioletear>'\n",
            " '<http://example.org/GreentailedTowhee>'\n",
            " '<http://example.org/GroovebilledAni>'\n",
            " '<http://example.org/HarrisSparrow>' '<http://example.org/HeermannGull>'\n",
            " '<http://example.org/HenslowSparrow>' '<http://example.org/HerringGull>'\n",
            " '<http://example.org/HoodedMerganser>'\n",
            " '<http://example.org/HoodedOriole>' '<http://example.org/HoodedWarbler>'\n",
            " '<http://example.org/HornedGrebe>' '<http://example.org/HornedLark>'\n",
            " '<http://example.org/HornedPuffin>' '<http://example.org/HouseSparrow>'\n",
            " '<http://example.org/HouseWren>' '<http://example.org/IndigoBunting>'\n",
            " '<http://example.org/IvoryGull>' '<http://example.org/KentuckyWarbler>'\n",
            " '<http://example.org/LaysanAlbatross>'\n",
            " '<http://example.org/LazuliBunting>'\n",
            " '<http://example.org/LeConteSparrow>' '<http://example.org/LeastAuklet>'\n",
            " '<http://example.org/LeastFlycatcher>' '<http://example.org/LeastTern>'\n",
            " '<http://example.org/LincolnSparrow>'\n",
            " '<http://example.org/LoggerheadShrike>'\n",
            " '<http://example.org/LongtailedJaeger>'\n",
            " '<http://example.org/LouisianaWaterthrush>'\n",
            " '<http://example.org/MagnoliaWarbler>' '<http://example.org/Mallard>'\n",
            " '<http://example.org/MangroveCuckoo>' '<http://example.org/MarshWren>'\n",
            " '<http://example.org/Mockingbird>' '<http://example.org/MourningWarbler>'\n",
            " '<http://example.org/MyrtleWarbler>'\n",
            " '<http://example.org/NashvilleWarbler>'\n",
            " '<http://example.org/NelsonSharptailedSparrow>'\n",
            " '<http://example.org/Nighthawk>' '<http://example.org/NorthernFlicker>'\n",
            " '<http://example.org/NorthernFulmar>'\n",
            " '<http://example.org/NorthernWaterthrush>'\n",
            " '<http://example.org/OlivesidedFlycatcher>'\n",
            " '<http://example.org/OrangecrownedWarbler>'\n",
            " '<http://example.org/OrchardOriole>' '<http://example.org/Ovenbird>'\n",
            " '<http://example.org/PacificLoon>' '<http://example.org/PaintedBunting>'\n",
            " '<http://example.org/PalmWarbler>' '<http://example.org/ParakeetAuklet>'\n",
            " '<http://example.org/PelagicCormorant>'\n",
            " '<http://example.org/PhiladelphiaVireo>'\n",
            " '<http://example.org/PiedKingfisher>'\n",
            " '<http://example.org/PiedbilledGrebe>'\n",
            " '<http://example.org/PigeonGuillemot>'\n",
            " '<http://example.org/PileatedWoodpecker>'\n",
            " '<http://example.org/PineGrosbeak>' '<http://example.org/PineWarbler>'\n",
            " '<http://example.org/PomarineJaeger>'\n",
            " '<http://example.org/PrairieWarbler>'\n",
            " '<http://example.org/ProthonotaryWarbler>'\n",
            " '<http://example.org/PurpleFinch>'\n",
            " '<http://example.org/RedbelliedWoodpecker>'\n",
            " '<http://example.org/RedbreastedMerganser>'\n",
            " '<http://example.org/RedcockadedWoodpecker>'\n",
            " '<http://example.org/RedeyedVireo>'\n",
            " '<http://example.org/RedfacedCormorant>'\n",
            " '<http://example.org/RedheadedWoodpecker>'\n",
            " '<http://example.org/RedleggedKittiwake>'\n",
            " '<http://example.org/RedwingedBlackbird>'\n",
            " '<http://example.org/RhinocerosAuklet>'\n",
            " '<http://example.org/RingbilledGull>'\n",
            " '<http://example.org/RingedKingfisher>' '<http://example.org/RockWren>'\n",
            " '<http://example.org/RosebreastedGrosbeak>'\n",
            " '<http://example.org/RubythroatedHummingbird>'\n",
            " '<http://example.org/RufousHummingbird>'\n",
            " '<http://example.org/RustyBlackbird>' '<http://example.org/SageThrasher>'\n",
            " '<http://example.org/SavannahSparrow>' '<http://example.org/Sayornis>'\n",
            " '<http://example.org/ScarletTanager>'\n",
            " '<http://example.org/ScissortailedFlycatcher>'\n",
            " '<http://example.org/ScottOriole>' '<http://example.org/SeasideSparrow>'\n",
            " '<http://example.org/ShinyCowbird>'\n",
            " '<http://example.org/SlatybackedGull>' '<http://example.org/SongSparrow>'\n",
            " '<http://example.org/SootyAlbatross>'\n",
            " '<http://example.org/SpottedCatbird>'\n",
            " '<http://example.org/SummerTanager>'\n",
            " '<http://example.org/SwainsonWarbler>'\n",
            " '<http://example.org/TennesseeWarbler>'\n",
            " '<http://example.org/TreeSparrow>' '<http://example.org/TreeSwallow>'\n",
            " '<http://example.org/TropicalKingbird>'\n",
            " '<http://example.org/VermilionFlycatcher>'\n",
            " '<http://example.org/VesperSparrow>' '<http://example.org/WarblingVireo>'\n",
            " '<http://example.org/WesternGrebe>' '<http://example.org/WesternGull>'\n",
            " '<http://example.org/WesternMeadowlark>'\n",
            " '<http://example.org/WesternWoodPewee>'\n",
            " '<http://example.org/WhippoorWill>' '<http://example.org/WhitePelican>'\n",
            " '<http://example.org/WhitebreastedKingfisher>'\n",
            " '<http://example.org/WhitebreastedNuthatch>'\n",
            " '<http://example.org/WhitecrownedSparrow>'\n",
            " '<http://example.org/WhiteeyedVireo>'\n",
            " '<http://example.org/WhiteneckedRaven>'\n",
            " '<http://example.org/WhitethroatedSparrow>'\n",
            " '<http://example.org/WilsonWarbler>' '<http://example.org/WinterWren>'\n",
            " '<http://example.org/WormeatingWarbler>'\n",
            " '<http://example.org/YellowWarbler>'\n",
            " '<http://example.org/YellowbelliedFlycatcher>'\n",
            " '<http://example.org/YellowbilledCuckoo>'\n",
            " '<http://example.org/YellowbreastedChat>'\n",
            " '<http://example.org/YellowheadedBlackbird>'\n",
            " '<http://example.org/YellowthroatedVireo>'\n",
            " '<http://example.org/greyCatbird>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relations = np.unique(X[:, 1])\n",
        "relations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEchqL3fATC-",
        "outputId": "0a67853f-5a5c-4cb4-bef5-82d82345011d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['<http://purl.obolibrary.org/obo/UBERON_0000022>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0000023>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0000033>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0000128>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0000180>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0000310>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0000341>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0000916>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0000970>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0000974>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0000978>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0001137>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0001443>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0001456>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0001467>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0001567>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0001684>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0002097>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0002387>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0002389>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0002415>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0003675>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0005094>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0006065>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0006846>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0008199>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0008200>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0010163>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0011810>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_0013702>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_2000006>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_2001463>',\n",
              "       '<http://purl.obolibrary.org/obo/UBERON_2002283>',\n",
              "       '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>',\n",
              "       '<http://www.w3.org/2000/01/rdf-schema#label>'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ampligraph.evaluation import train_test_split_no_unseen \n",
        "\n",
        "num_test = int(len(X) * (20 / 100))\n",
        "data = {}\n",
        "data['train'], data['test'] = train_test_split_no_unseen(X, test_size=num_test, seed=0, allow_duplication=False) "
      ],
      "metadata": {
        "id": "rdiXbT5RAYkt"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RshQCjgegQX"
      },
      "source": [
        "from ampligraph.latent_features import ConvE"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgAcQ1g3egQe"
      },
      "source": [
        "Lets go through the parameters to understand what's going on:\n",
        "\n",
        "- **`k`** : the dimensionality of the embedding space\n",
        "- **`eta`** ($\\eta$) : the number of negative, or false triples that must be generated at training runtime for each positive, or true triple\n",
        "- **`batches_count`** : the number of batches in which the training set is split during the training loop. If you are having into low memory issues than settings this to a higher number may help.\n",
        "- **`epochs`** : the number of epochs to train the model for.\n",
        "- **`optimizer`** : the Adam optimizer, with a learning rate of 1e-3 set via the *optimizer_params* kwarg.\n",
        "- **`loss`** : pairwise loss, with a margin of 0.5 set via the *loss_params* kwarg.\n",
        "- **`regularizer`** : $L_p$ regularization with $p=2$, i.e. l2 regularization. $\\lambda$ = 1e-5, set via the *regularizer_params* kwarg. \n",
        "\n",
        "Now we can instantiate the model:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap1Yd4LEegQg"
      },
      "source": [
        "amp = ComplEx(batches_count=99, \n",
        "                seed=0, \n",
        "                epochs=500, \n",
        "                k=150, \n",
        "                eta=5,\n",
        "                optimizer='adam', \n",
        "                optimizer_params={'lr':3e-5}, #1e-3\n",
        "                loss='multiclass_nll', \n",
        "                regularizer='LP', \n",
        "                regularizer_params={'p':3, 'lambda':1e-5}, \n",
        "                verbose=True)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaJeVr-megQq"
      },
      "source": [
        "## Filtering negatives\n",
        "\n",
        "AmpliGraph aims to follow scikit-learn's ease-of-use design philosophy and simplify everything down to **`fit`**, **`evaluate`**, and **`predict`** functions. \n",
        "\n",
        "However, there are some knowledge graph specific steps we must take to ensure our model can be trained and evaluated correctly. The first of these is defining the filter that will be used to ensure that no *negative* statements generated by the corruption procedure are actually positives. This is simply done by concatenating our train and test sets. Now when negative triples are generated by the corruption strategy, we can check that they aren't actually true statements.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edjJcTReegQs"
      },
      "source": [
        "positives_filter = X"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcI2mTwSegRh"
      },
      "source": [
        "## Fitting the model\n",
        "\n",
        "Once you run the next cell the model will train. \n",
        "\n",
        "On a modern laptop this should take ~3 minutes (although your mileage may vary, especially if you've changed any of the hyper-parameters above)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CebLOmJWegRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3535a19-57ec-4798-8057-ce0d55912b16"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "amp.fit(data['train'], early_stopping = False)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average ComplEx Loss:   0.257889: 100%|██████████| 500/500 [03:19<00:00,  2.51epoch/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ampligraph.evaluation import evaluate_performance"
      ],
      "metadata": {
        "id": "_gwKyyJht5Gn"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = evaluate_performance(data['test'], \n",
        "                             model=amp, \n",
        "                             filter_triples=positives_filter,   # Corruption strategy filter defined above \n",
        "                             use_default_protocol=True, # corrupt subj and obj separately while evaluating\n",
        "                             verbose=True)"
      ],
      "metadata": {
        "id": "6GTjlVKst6Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ampligraph.evaluation import mr_score, mrr_score, hits_at_n_score\n",
        "\n",
        "mrr = mrr_score(ranks)\n",
        "print(\"MRR: %.2f\" % (mrr))\n",
        "\n",
        "hits_10 = hits_at_n_score(ranks, n=10)\n",
        "print(\"Hits@10: %.2f\" % (hits_10))\n",
        "hits_3 = hits_at_n_score(ranks, n=3)\n",
        "print(\"Hits@3: %.2f\" % (hits_3))\n",
        "hits_1 = hits_at_n_score(ranks, n=1)\n",
        "print(\"Hits@1: %.2f\" % (hits_1))"
      ],
      "metadata": {
        "id": "Pbn8_BGht-zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89U5Ck5GegSn"
      },
      "source": [
        "---\n",
        "# 4.  Extract KGE "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from ampligraph.latent_features import ComplEx\n",
        "kg_embeddings = amp.get_embeddings(entities)\n",
        "print(kg_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3idsEpGAgsZ",
        "outputId": "cab82602-ef76-4228-a3a1-65cd6c7e219b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/gdrive/MyDrive/caltech_birds-master/aab_bird_desc.xlsx')\n",
        "color = df['Family']\n",
        "order = df['Order']"
      ],
      "metadata": {
        "id": "TZ_Y_X1dKwI_"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "X_embedded = TSNE(n_components=2, perplexity = 20, learning_rate='auto',init='random').fit_transform(kg_embeddings)\n",
        "sns.set(rc={'figure.figsize':(10,8)})\n",
        "sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=order, legend=False)"
      ],
      "metadata": {
        "id": "Q4rCuQSWAp83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ESZSL"
      ],
      "metadata": {
        "id": "NgHRlWL8__67"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "TUSnnB6jDLWK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import scipy.io\n",
        "from sklearn.metrics import classification_report,confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "wZm5BrRxDLWQ"
      },
      "outputs": [],
      "source": [
        "#Please add the folder name of the dataset to run it on different dataset.\n",
        "dataset = 'CUB'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6mvBGesDLWR"
      },
      "source": [
        "From the .mat files extract all the features from resnet and the attribute splits. \n",
        "- The res101 contains features and the corresponding labels.\n",
        "- att_splits contains the different splits for trainval, train, val and test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "Ym32EldqDLWW"
      },
      "outputs": [],
      "source": [
        "res101 = scipy.io.loadmat('/content/gdrive/MyDrive/caltech_birds-master/CUB/res101.mat')\n",
        "#res101 = models.resnet50(pretrained=True)\n",
        "att_splits = scipy.io.loadmat('/content/gdrive/MyDrive/caltech_birds-master/CUB/att_splits.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8JHa5-ZDLWX"
      },
      "outputs": [],
      "source": [
        "res101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAT8DVzGDLWY"
      },
      "outputs": [],
      "source": [
        "att_splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "boUBpHPLDLWZ"
      },
      "outputs": [],
      "source": [
        "#Using the correct naming conventions to get the loctions\n",
        "trainval_loc = 'trainval_loc'\n",
        "train_loc = 'train_loc'\n",
        "val_loc = 'val_loc'\n",
        "test_loc = 'test_unseen_loc'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8KwVfT3DLWa"
      },
      "source": [
        "We need the corresponding ground-truth labels/classes for each training example for all our train, val, trainval and test set according to the split locations provided.\n",
        "In this example we have used the `CUB` dataset which has 200 unique classes overall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "1jri9kYcDLWd"
      },
      "outputs": [],
      "source": [
        "labels = res101['labels']\n",
        "labels_train = labels[np.squeeze(att_splits[train_loc]-1)] #get labels for training\n",
        "labels_val = labels[np.squeeze(att_splits[val_loc]-1)]\n",
        "labels_trainval = labels[np.squeeze(att_splits[trainval_loc]-1)]\n",
        "labels_test = labels[np.squeeze(att_splits[test_loc]-1)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "00JKtcjCDLWe",
        "outputId": "a25bcc07-1856-483c-c222-8392e2bc454f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[151],\n",
              "       [151],\n",
              "       [151],\n",
              "       [151],\n",
              "       [151],\n",
              "       [151],\n",
              "       [151],\n",
              "       [151],\n",
              "       [151],\n",
              "       [151]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "labels_train[:10,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "iCDj8aiPDLWy",
        "outputId": "397c0d08-a378-4cb3-9b2b-8ddda2998ce6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
              "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
              "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
              "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
              "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
              "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
              "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
              "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
              "       196, 197, 198, 199, 200], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "unique_labels = np.unique(labels)\n",
        "unique_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Oyo6xLaDLWz"
      },
      "source": [
        "In a typical zero-shot learning scenario, there are no overlapping classes between training and testing phase, i.e the train classes are completely different from the test classes. So let us verify if there are any overlapping classes in the test and train scenario.\n",
        "- During training phase we have `z` classes\n",
        "- During the testing phase we have `z'` classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "hcgiKUPgDLW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "592f21a2-9adc-464d-9bd7-82adc4371882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1   2   5   6   8   9  10  11  13  14  15  16  17  18  20  22  23  24\n",
            "  25  26  27  28  30  31  33  35  38  39  41  43  46  47  48  51  54  57\n",
            "  59  60  61  63  65  66  67  70  73  74  75  76  78  81  85  86  89  90\n",
            "  93  94  96  97  99 103 106 107 109 112 114 118 119 123 126 127 128 131\n",
            " 132 134 136 144 147 149 151 153 154 156 162 164 165 169 172 177 178 180\n",
            " 181 183 188 190 194 196 197 198 199 200]\n"
          ]
        }
      ],
      "source": [
        "train_labels_seen = np.unique(labels_train)\n",
        "val_labels_unseen = np.unique(labels_val)\n",
        "trainval_labels_seen = np.unique(labels_trainval)\n",
        "test_labels_unseen = np.unique(labels_test)\n",
        "print(train_labels_seen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "GUcimobvDLW2",
        "outputId": "8ebe2ea1-6aa1-43a3-d2df-6c82ee268ae8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of overlapping classes between train and val: 0\n",
            "Number of overlapping classes between trainval and test: 0\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of overlapping classes between train and val:\",len(set(train_labels_seen).intersection(set(val_labels_unseen))))\n",
        "print(\"Number of overlapping classes between trainval and test:\",len(set(trainval_labels_seen).intersection(set(test_labels_unseen))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "ySVbjRbTDLW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09843c1b-4608-4ebe-fbde-0be8a304391b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1   2   5   6   8   9  10  11  13  14  15  16  17  18  20  22  23  24\n",
            "  25  26  27  28  30  31  33  35  38  39  41  43  46  47  48  51  54  57\n",
            "  59  60  61  63  65  66  67  70  73  74  75  76  78  81  85  86  89  90\n",
            "  93  94  96  97  99 103 106 107 109 112 114 118 119 123 126 127 128 131\n",
            " 132 134 136 144 147 149 151 153 154 156 162 164 165 169 172 177 178 180\n",
            " 181 183 188 190 194 196 197 198 199 200]\n",
            "[  7  19  21  29  34  36  50  56  62  68  69  72  79  80  87  88  91  95\n",
            "  98 100 104 108 116 120 122 124 125 129 139 141 142 150 152 157 159 160\n",
            " 166 167 171 174 176 179 182 185 187 189 191 192 193 195]\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "for labels in train_labels_seen:\n",
        "    labels_train[labels_train == labels] = i    \n",
        "    i = i+1\n",
        "j = 0\n",
        "for labels in val_labels_unseen:\n",
        "    labels_val[labels_val == labels] = j\n",
        "    j = j+1\n",
        "k = 0\n",
        "for labels in trainval_labels_seen:\n",
        "    labels_trainval[labels_trainval == labels] = k\n",
        "    k = k+1\n",
        "l = 0\n",
        "for labels in test_labels_unseen:\n",
        "    labels_test[labels_test == labels] = l\n",
        "    l = l+1\n",
        "\n",
        "#used for relabeling     \n",
        "print(train_labels_seen)\n",
        "print(test_labels_unseen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE8FPllKDLW3"
      },
      "source": [
        "Let us denote the features X ∈ [d×m] available at training stage, where d is the dimensionality\n",
        "of the data, and m is the number of instances. We are useing resnet features which are extracted from `CUB` dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "5rAdWGBTDLW6"
      },
      "outputs": [],
      "source": [
        "X_features = res101['features']\n",
        "train_vec = X_features[:,np.squeeze(att_splits[train_loc]-1)]\n",
        "val_vec = X_features[:,np.squeeze(att_splits[val_loc]-1)]\n",
        "trainval_vec = X_features[:,np.squeeze(att_splits[trainval_loc]-1)]\n",
        "test_vec = X_features[:,np.squeeze(att_splits[test_loc]-1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "4_XtfDoNDLXC",
        "outputId": "81556d69-9af8-4d68-9942-074d824fc63f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features for train: (2048, 5875)\n",
            "Features for val: (2048, 2946)\n",
            "Features for trainval: (2048, 7057)\n",
            "Features for test: (2048, 2967)\n"
          ]
        }
      ],
      "source": [
        "print(\"Features for train:\", train_vec.shape)\n",
        "print(\"Features for val:\", val_vec.shape)\n",
        "print(\"Features for trainval:\", trainval_vec.shape)\n",
        "print(\"Features for test:\", test_vec.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSvcHfRBDLXC"
      },
      "source": [
        "#### Normalize the vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "oB22QXiiDLXD"
      },
      "outputs": [],
      "source": [
        "def normalization(vec,mean,std):\n",
        "    sol = vec - mean\n",
        "    sol1 = sol/std\n",
        "    return sol1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "aog2uSrHDLXE"
      },
      "outputs": [],
      "source": [
        "train_mean = train_vec.mean(axis=1, keepdims=True)\n",
        "train_std = np.std(train_vec, axis=1, keepdims = True)\n",
        "trainval_mean = trainval_vec.mean(axis=1, keepdims = True)\n",
        "trainval_std = np.std(trainval_vec, axis=1, keepdims=True)\n",
        "\n",
        "train_vec = normalization(train_vec, train_mean, train_std)\n",
        "val_vec = normalization(val_vec, train_mean, train_std)\n",
        "\n",
        "trainval_vec = normalization(trainval_vec, trainval_mean, trainval_std)\n",
        "test_vec = normalization(test_vec, trainval_mean, trainval_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMzheHdpDLXF"
      },
      "source": [
        "Each of the classes in the dataset have an attribute (a) description. This vector is known as the `Signature matrix` of dimension S ∈ [0, 1]a×z. For training stage there are z classes and z' classes  for test S ∈ [0, 1]a×z'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "z8xJpjg9DLXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d329eb8d-7d68-47fe-c6a6-211319c59565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 100)\n"
          ]
        }
      ],
      "source": [
        "signature = kg_embeddings.transpose() #the kge gets sorted here; transpose to match the shape of the original attributes\n",
        "train_sig = signature[:,(train_labels_seen)-1]\n",
        "val_sig = signature[:,(val_labels_unseen)-1]\n",
        "trainval_sig = signature[:,(trainval_labels_seen)-1]\n",
        "test_sig = signature[:,(test_labels_unseen)-1]\n",
        "print(train_sig.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL_8k3EKDLXP"
      },
      "source": [
        "This is a signature matrix, where the occurance of an attribute corresponding to the class is give.\n",
        "For instance, if the classes are `horse` and `zebra` and the corresponding attributes are [wild_animal, 4_legged, carnivore]\n",
        "\n",
        "```\n",
        " Horse      Zebra\n",
        "[0.00354613 0.        ] Domestic_animal\n",
        "[0.13829921 0.20209503] 4_legged\n",
        "[0.06560347 0.04155225] carnivore\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "UIEv1ntLDLXQ",
        "outputId": "2b876714-a44c-4960-c6bc-4769734bbc77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.09150717  0.01566118]\n",
            " [-0.1190209  -0.15038627]\n",
            " [ 0.16520041 -0.05978232]]\n"
          ]
        }
      ],
      "source": [
        "print(train_sig[3:6,:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "bPOxmz_mDLXQ",
        "outputId": "c207160a-e17f-45e4-f834-e319ec5605d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Signature for train: (200, 100)\n",
            "Signature for val: (200, 50)\n",
            "Signature for trainval: (200, 150)\n",
            "Signature for test: (200, 50)\n"
          ]
        }
      ],
      "source": [
        "print(\"Signature for train:\", train_sig.shape)\n",
        "print(\"Signature for val:\", val_sig.shape)\n",
        "print(\"Signature for trainval:\", trainval_sig.shape)\n",
        "print(\"Signature for test:\", test_sig.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "Hg_6wsf1DLXR"
      },
      "outputs": [],
      "source": [
        "#params for train and val set\n",
        "m_train = labels_train.shape[0]\n",
        "n_val = labels_val.shape[0]\n",
        "z_train = len(train_labels_seen)\n",
        "z1_val = len(val_labels_unseen)\n",
        "\n",
        "#params for trainval and test set\n",
        "m_trainval = labels_trainval.shape[0]\n",
        "n_test = labels_test.shape[0]\n",
        "z_trainval = len(trainval_labels_seen)\n",
        "z1_test = len(test_labels_unseen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKH2u4qyDLXR"
      },
      "source": [
        "The ground truth is a one-hot encoded vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "qNytqSCoDLXR"
      },
      "outputs": [],
      "source": [
        "#ground truth for train and val set\n",
        "gt_train = 0*np.ones((m_train, z_train))\n",
        "gt_train[np.arange(m_train), np.squeeze(labels_train)] = 1\n",
        "\n",
        "#grountruth for trainval and test set\n",
        "gt_trainval = 0*np.ones((m_trainval, z_trainval))\n",
        "gt_trainval[np.arange(m_trainval), np.squeeze(labels_trainval)] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "30Lfu3UNDLXT",
        "outputId": "ae46d7b6-4169-43b9-c706-e03c4670ec21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "gt_train[:1,:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "q0QYwBcTDLXU"
      },
      "outputs": [],
      "source": [
        "#train set\n",
        "d_train = train_vec.shape[0]\n",
        "a_train = train_sig.shape[0]\n",
        "\n",
        "#Weights\n",
        "V = np.zeros((d_train,a_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "fAVu-kviDLXU"
      },
      "outputs": [],
      "source": [
        "#trainval set\n",
        "d_trainval = trainval_vec.shape[0]\n",
        "a_trainval = trainval_sig.shape[0]\n",
        "W = np.zeros((d_trainval,a_trainval))\n",
        "\n",
        "#Note: These hyper-parameters were found using the code snippet available below\n",
        "gamm1 = 2\n",
        "alph1 = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_F-wjs0DLXV"
      },
      "source": [
        "The one-line code solution proposed.\n",
        "```\n",
        "V = inverse(XX' + γI) XYS' inverse(SS' + λI)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "49E2AhOwDLXV"
      },
      "outputs": [],
      "source": [
        "part_1_test = np.linalg.pinv(np.matmul(trainval_vec, trainval_vec.transpose()) + (10**alph1)*np.eye(d_trainval))\n",
        "part_0_test = np.matmul(np.matmul(trainval_vec,gt_trainval),trainval_sig.transpose())\n",
        "part_2_test = np.linalg.pinv(np.matmul(trainval_sig, trainval_sig.transpose()) + (10**gamm1)*np.eye(a_trainval))\n",
        "\n",
        "W = np.matmul(np.matmul(part_1_test,part_0_test),part_2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOuRh6fxDLXV"
      },
      "source": [
        "For inference stage, \n",
        "```\n",
        "argmax(x'VS)\n",
        "```\n",
        "Where S is the signature matrix of the test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "XCjIGbGADLXV"
      },
      "outputs": [],
      "source": [
        "#predictions\n",
        "outputs_1 = np.matmul(np.matmul(test_vec.transpose(),W),test_sig)\n",
        "preds_1 = np.array([np.argmax(output) for output in outputs_1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygt7JC16DLXW"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(labels_test, preds_1)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "avg = sum(cm.diagonal())/len(test_labels_unseen)\n",
        "print(\"The top 1% accuracy is:\", avg*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOOnHnEJDLbZ"
      },
      "source": [
        "------------------------------------------------------------------------------------------------\n",
        "The below code snippet can be used to find the best hyper-parameter using the train and val set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "V6SCRbvKDLba",
        "outputId": "8b89771f-d8b4-4c21-9463-f7601a3784f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 1\n"
          ]
        }
      ],
      "source": [
        "accu = 0.10\n",
        "alph1 = 3\n",
        "gamm1 = 1\n",
        "for alpha in range(-3, 4):\n",
        "    for gamma in range(-3,4):\n",
        "        #One line solution\n",
        "        part_1 = np.linalg.pinv(np.matmul(train_vec, train_vec.transpose()) + (10**alpha)*np.eye(d_train))\n",
        "        part_0 = np.matmul(np.matmul(train_vec,gt_train),train_sig.transpose())\n",
        "        part_2 = np.linalg.pinv(np.matmul(train_sig, train_sig.transpose()) + (10**gamma)*np.eye(a_train))\n",
        "\n",
        "        V = np.matmul(np.matmul(part_1,part_0),part_2)\n",
        "        #print(V)\n",
        "\n",
        "        #predictions\n",
        "        outputs = np.matmul(np.matmul(val_vec.transpose(),V),val_sig)\n",
        "        preds = np.array([np.argmax(output) for output in outputs])\n",
        "\n",
        "        #print(accuracy_score(labels_val,preds))\n",
        "        cm = confusion_matrix(labels_val, preds)\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        avg = sum(cm.diagonal())/len(val_labels_unseen)\n",
        "        #print(\"Avg:\", avg, alpha, gamma)\n",
        "\n",
        "        if avg > accu:\n",
        "            accu = avg\n",
        "            alph1 = alpha\n",
        "            gamm1 = gamma\n",
        "print(alph1, gamm1)"
      ]
    }
  ],
  "metadata": {
    "environment": {
      "name": "pytorch-gpu.1-4.m46",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
    },
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "KGE_ESZSL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}